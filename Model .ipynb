{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahil1239/Fall-Prediction-ELC/blob/main/Model%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CxTuSivEHls"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers, losses\n",
        "import pickle\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SfzIM97PH6yF",
        "outputId": "1f1a520b-b18a-470e-c813-e8a04c179df2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s82-r1TTEUaI",
        "outputId": "f8d506a1-b006-494b-89c0-acaab84f16e8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "path = \"./\"\n",
        "\n",
        "# Load the training data from CSV files\n",
        "train_x = pd.read_csv(path + 'train_x.csv')\n",
        "train_y = pd.read_csv(path + 'train_y.csv')\n",
        "test_x = pd.read_csv(path + 'test_x.csv')\n",
        "test_y = pd.read_csv(path + 'test_y.csv')\n",
        "\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n",
        "print(test_x.shape)\n",
        "print(test_y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOA7lWFnEbC2",
        "outputId": "a6d3b3df-c514-4a0d-ce39-c5daea41e13a"
      },
      "outputs": [],
      "source": [
        "unique_values, counts = np.unique(train_y, return_counts=True)\n",
        "print(unique_values, counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxbX9Bg5FzEo",
        "outputId": "823b4717-ccc9-4df2-d7fa-26ef38f8e643"
      },
      "outputs": [],
      "source": [
        "unique_values, counts = np.unique(test_y, return_counts=True)\n",
        "print(unique_values, counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dk9sK-ilF09u"
      },
      "outputs": [],
      "source": [
        "n_timesteps = 50\n",
        "n_features = 9\n",
        "n_outputs = 1\n",
        "\n",
        "def hybrid_model():\n",
        "\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # First CNN layer\n",
        "\n",
        "    model.add(layers.Conv1D(kernel_size=5,\n",
        "                            filters=64,\n",
        "                            activation='relu',\n",
        "                            input_shape=(n_timesteps, n_features)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "    model.add(layers.MaxPooling1D(3, strides=2, padding=\"valid\"))\n",
        "\n",
        "    # Second CNN layer\n",
        "\n",
        "    model.add(layers.Conv1D(kernel_size=5,\n",
        "                            filters=64,\n",
        "                            activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "    model.add(layers.MaxPooling1D(3, strides=2, padding=\"valid\"))\n",
        "\n",
        "    # Third CNN layer\n",
        "\n",
        "    model.add(layers.Conv1D(kernel_size=5,\n",
        "                            filters=64,\n",
        "                            activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "    model.add(layers.MaxPooling1D(3, strides=2, padding=\"valid\"))\n",
        "\n",
        "    model.add(layers.Dense(64))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    # First LSTM\n",
        "    model.add(layers.LSTM(64, return_sequences=True))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    # Second LSTM\n",
        "    model.add(layers.LSTM(64, return_sequences=True))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(n_outputs, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "\n",
        "    opt = optimizers.Adam(learning_rate=0.0005)\n",
        "    lss = losses.BinaryFocalCrossentropy()\n",
        "    model.compile(loss=lss, optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrm7TLNhGBIA",
        "outputId": "234c2e38-e7e8-41d2-c2a5-d60a8be78b2d"
      },
      "outputs": [],
      "source": [
        "n_epochs = 200\n",
        "model = hybrid_model()\n",
        "history = model.fit(train_x, train_y, validation_data=(test_x, test_y), epochs = n_epochs, batch_size = 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OUgbdt0Ib7-",
        "outputId": "e65e7c93-e3be-47a2-c17f-cd19a957a40d"
      },
      "outputs": [],
      "source": [
        "y_pred =np.squeeze(model.predict(test_x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5vdPKkORjrN"
      },
      "outputs": [],
      "source": [
        "for i in range(len(y_pred)):\n",
        "  if y_pred[i]>0.5:\n",
        "    y_pred[i]=1\n",
        "  else:\n",
        "    y_pred[i]=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQAIx3TJTB_X",
        "outputId": "dcb030fa-b381-4908-e8f8-1e4d120c44c5"
      },
      "outputs": [],
      "source": [
        "unique_values, counts = np.unique(test_y, return_counts=True)\n",
        "print(unique_values, counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32HSavWRUgeF",
        "outputId": "f7557612-ddad-482a-afff-8700c1bb54a0"
      },
      "outputs": [],
      "source": [
        "unique_values, counts = np.unique(y_pred, return_counts=True)\n",
        "print(unique_values, counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j76p3r5CVQCd",
        "outputId": "08bcd69d-e32d-4507-eaf4-5a90e2241df6"
      },
      "outputs": [],
      "source": [
        "print(classification_report(test_y, y_pred, target_names=['no fall', 'fall']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWpYR2BrVrT9",
        "outputId": "9d955e24-9528-4ad4-d5c8-b82ac61a312a"
      },
      "outputs": [],
      "source": [
        "print(confusion_matrix(test_y, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21GE3lbDLFvk"
      },
      "outputs": [],
      "source": [
        "model.save(\"model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "modified_data = './data_File.csv'\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv(modified_data)\n",
        "\n",
        "# Separate the features (X) and the target variable (y)\n",
        "X = df.drop(['Output'], axis=1).values\n",
        "y = df['Output'].values\n",
        "\n",
        "# Split the data into train and test sets, stratifying based on the 'Output' column\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Print the train and test set shapes to verify the proportions\n",
        "print(\"Train Set - Not Fall: {}, Fall: {}\".format(np.sum(y_train == 0), np.sum(y_train == 1)))\n",
        "print(\"Test Set - Not Fall: {}, Fall: {}\".format(np.sum(y_test == 0), np.sum(y_test == 1)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# importing file in df\n",
        "df = pd.read_csv('./data_File.csv')\n",
        "\n",
        "x = np.array(df.drop(['Output'], axis=1))\n",
        "y = np.array(df['Output'])\n",
        "\n",
        "group_size = 50\n",
        "num_groups = len(df) // group_size\n",
        "\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "for i in range(num_groups):\n",
        "    start_index = i * group_size\n",
        "    end_index = (i + 1) * group_size\n",
        "\n",
        "    inp = x[start_index:end_index]\n",
        "    unique_values, counts = np.unique(y[start_index:end_index], return_counts=True)\n",
        "    majority_element = unique_values[np.argmax(counts)]\n",
        "\n",
        "    inputs.append(inp)\n",
        "    outputs.append(majority_element)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Combine inputs and outputs into a single DataFrame\n",
        "df_combined = pd.DataFrame({'Inputs': inputs, 'Outputs': outputs})\n",
        "\n",
        "# Split the combined DataFrame into train and test sets\n",
        "train_df, test_df = train_test_split(df_combined, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split the train and test sets into input and output DataFrames\n",
        "train_x_df = pd.concat([train_df['Inputs']], ignore_index=True)\n",
        "train_y_df = pd.DataFrame(train_df['Outputs'])\n",
        "test_x_df = pd.concat([test_df['Inputs']], ignore_index=True)\n",
        "test_y_df = pd.DataFrame(test_df['Outputs'])\n",
        "\n",
        "# Save the train and test sets to separate CSV files\n",
        "train_x_df.to_csv('train_x.csv', index=False)\n",
        "train_y_df.to_csv('train_y.csv', index=False)\n",
        "test_x_df.to_csv('test_x.csv', index=False)\n",
        "test_y_df.to_csv('test_y.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyP0uoTfh8K1Olm6HgO20Rhv",
      "gpuType": "T4",
      "include_colab_link": true,
      "mount_file_id": "1v8JTUQ1BqYCLMzlp1f6OV-9w_ikB_tqs",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
