{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahil1239/Fall-Prediction-ELC/blob/main/Model%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1CxTuSivEHls"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers, losses\n",
        "import pickle\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SfzIM97PH6yF",
        "outputId": "1f1a520b-b18a-470e-c813-e8a04c179df2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s82-r1TTEUaI",
        "outputId": "f8d506a1-b006-494b-89c0-acaab84f16e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(669, 50, 9)\n",
            "(669,)\n",
            "(168, 50, 9)\n",
            "(168,)\n"
          ]
        }
      ],
      "source": [
        "path = \"./Early_Fall_Prediction\"\n",
        "with open(path+'/xc1_train.pkl','rb') as f:\n",
        "  train_x = pickle.load(f)\n",
        "with open(path+'/yc1_train.pkl','rb') as f:\n",
        "  train_y = pickle.load(f)\n",
        "with open(path+'/xc1_test.pkl','rb') as f:\n",
        "  test_x = pickle.load(f)\n",
        "with open(path+'/yc1_test.pkl','rb') as f:\n",
        "  test_y = pickle.load(f)\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n",
        "print(test_x.shape)\n",
        "print(test_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOA7lWFnEbC2",
        "outputId": "a6d3b3df-c514-4a0d-ce39-c5daea41e13a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1] [242 427]\n"
          ]
        }
      ],
      "source": [
        "unique_values, counts = np.unique(train_y, return_counts=True)\n",
        "print(unique_values, counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxbX9Bg5FzEo",
        "outputId": "823b4717-ccc9-4df2-d7fa-26ef38f8e643"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1] [ 59 109]\n"
          ]
        }
      ],
      "source": [
        "unique_values, counts = np.unique(test_y, return_counts=True)\n",
        "print(unique_values, counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Dk9sK-ilF09u"
      },
      "outputs": [],
      "source": [
        "n_timesteps = 50\n",
        "n_features = 9\n",
        "n_outputs = 1\n",
        "\n",
        "def hybrid_model():\n",
        "\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # First CNN layer\n",
        "\n",
        "    model.add(layers.Conv1D(kernel_size=5,\n",
        "                            filters=64,\n",
        "                            activation='relu',\n",
        "                            input_shape=(n_timesteps, n_features)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "    model.add(layers.MaxPooling1D(3, strides=2, padding=\"valid\"))\n",
        "\n",
        "    # Second CNN layer\n",
        "\n",
        "    model.add(layers.Conv1D(kernel_size=5,\n",
        "                            filters=64,\n",
        "                            activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "    model.add(layers.MaxPooling1D(3, strides=2, padding=\"valid\"))\n",
        "\n",
        "    # Third CNN layer\n",
        "\n",
        "    model.add(layers.Conv1D(kernel_size=5,\n",
        "                            filters=64,\n",
        "                            activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.ReLU())\n",
        "    model.add(layers.MaxPooling1D(3, strides=2, padding=\"valid\"))\n",
        "\n",
        "    model.add(layers.Dense(64))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    # First LSTM\n",
        "    model.add(layers.LSTM(64, return_sequences=True))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    # Second LSTM\n",
        "    model.add(layers.LSTM(64, return_sequences=True))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(n_outputs, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "\n",
        "    opt = optimizers.Adam(learning_rate=0.0005)\n",
        "    lss = losses.BinaryFocalCrossentropy()\n",
        "    model.compile(loss=lss, optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrm7TLNhGBIA",
        "outputId": "234c2e38-e7e8-41d2-c2a5-d60a8be78b2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_3 (Conv1D)           (None, 46, 64)            2944      \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 46, 64)            256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_3 (ReLU)              (None, 46, 64)            0         \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPoolin  (None, 22, 64)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 18, 64)            20544     \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 18, 64)            256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_4 (ReLU)              (None, 18, 64)            0         \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPoolin  (None, 8, 64)             0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 4, 64)             20544     \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 4, 64)             256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_5 (ReLU)              (None, 4, 64)             0         \n",
            "                                                                 \n",
            " max_pooling1d_5 (MaxPoolin  (None, 1, 64)             0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1, 64)             4160      \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 1, 64)             256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1, 64)             0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 1, 64)             33024     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 1, 64)             0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 1, 64)             33024     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 1, 64)             0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 115329 (450.50 KB)\n",
            "Trainable params: 114817 (448.50 KB)\n",
            "Non-trainable params: 512 (2.00 KB)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "11/11 [==============================] - 9s 140ms/step - loss: 0.1697 - accuracy: 0.5994 - val_loss: 0.1735 - val_accuracy: 0.4821\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.1587 - accuracy: 0.7683 - val_loss: 0.1792 - val_accuracy: 0.3512\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.1451 - accuracy: 0.8221 - val_loss: 0.1820 - val_accuracy: 0.3571\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.1242 - accuracy: 0.8864 - val_loss: 0.1747 - val_accuracy: 0.3929\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.0969 - accuracy: 0.9537 - val_loss: 0.1418 - val_accuracy: 0.7440\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.0662 - accuracy: 0.9865 - val_loss: 0.0958 - val_accuracy: 0.9702\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.0426 - accuracy: 0.9925 - val_loss: 0.0543 - val_accuracy: 0.9940\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 0.9881\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9881\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 0.9881\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9881\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 0.9881\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9881\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 0.9881\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9881\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9881\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9881\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9881\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9881\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9881\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9881\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 7.3584e-04 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9881\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 8.9537e-04 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9881\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 6.2053e-04 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9881\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 0s 42ms/step - loss: 5.9224e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9881\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 0s 38ms/step - loss: 4.7949e-04 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9881\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 0s 39ms/step - loss: 5.8658e-04 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9881\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 5.1170e-04 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 0.9881\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 3.6265e-04 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 0.9881\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 0s 39ms/step - loss: 4.3966e-04 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 0.9881\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 5.1312e-04 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 0.9881\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 3.6709e-04 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 0.9881\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 2.7267e-04 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 0.9881\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.9857e-04 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 0.9881\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 3.5324e-04 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 0.9881\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 0s 38ms/step - loss: 2.9610e-04 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 0.9881\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 3.2457e-04 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 0.9881\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 2.9560e-04 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 0.9881\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.9534e-04 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 0.9881\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.6914e-04 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9881\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 2.7075e-04 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9881\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 2.1364e-04 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9881\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 1.9092e-04 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9881\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 0s 41ms/step - loss: 1.7061e-04 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 0.9881\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 1.5162e-04 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 0.9881\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.6803e-04 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 0.9881\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 2.0665e-04 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9881\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 1.4074e-04 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9881\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 1.8280e-04 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 0.9881\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 1.2811e-04 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 0.9881\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 1.2559e-04 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 0.9881\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 1.1848e-04 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 0.9881\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 1.5863e-04 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9881\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.1994e-04 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9881\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.3347e-04 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9881\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 1.0988e-04 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9881\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 1.3696e-04 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 0.9881\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 1.1896e-04 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 0.9881\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 1.0408e-04 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 0.9881\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 1.2051e-04 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9881\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 1.0738e-04 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9881\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 1.0983e-04 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 0.9881\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 1.1110e-04 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9881\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 8.7269e-05 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 0.9881\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 1.1242e-04 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 0.9881\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 6.8491e-05 - accuracy: 1.0000 - val_loss: 0.0285 - val_accuracy: 0.9881\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 9.9829e-05 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 0.9881\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 6.2217e-05 - accuracy: 1.0000 - val_loss: 0.0283 - val_accuracy: 0.9881\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 9.2894e-05 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 0.9881\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 8.7666e-05 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.9881\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 6.7956e-05 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.9881\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 7.7740e-05 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 0.9881\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 7.0848e-05 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9881\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 4.5474e-05 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 0.9881\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 8.8734e-05 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9881\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 8.7339e-05 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 0.9881\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 6.7845e-05 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 0.9881\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 5.6961e-05 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9881\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 4.8430e-05 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9881\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 3.6619e-05 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 0.9881\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 6.4286e-05 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9881\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 4.3321e-05 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9881\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 3.8758e-05 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9881\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 5.2660e-05 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9881\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 5.8963e-05 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 0.9881\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 4.6955e-05 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 0.9881\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 4.5908e-05 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 0.9881\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 4.4674e-05 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 0.9881\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 4.6192e-05 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 0.9881\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 2.7952e-05 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 0.9881\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 3.7593e-05 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9881\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 3.3297e-05 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9881\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 4.8829e-05 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 0.9881\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 4.3031e-05 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 0.9881\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 5.4120e-05 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 0.9881\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 2.9957e-05 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9881\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 3.8043e-05 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 0.9881\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 5.1158e-05 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 0.9881\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 3.4965e-05 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9881\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 4.5588e-05 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9881\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 4.8210e-05 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9881\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 3.7470e-05 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9881\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 3.5367e-05 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9881\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 3.6753e-05 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9881\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 3.7359e-05 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 0.9881\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 3.2169e-05 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 0.9881\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 4.1079e-05 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 0.9881\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 5.3240e-05 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9881\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 3.0959e-05 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9881\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 3.3308e-05 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9881\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 4.3562e-05 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9881\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 4.6642e-05 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9881\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 1.7686e-05 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9881\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 2.7360e-05 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9881\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 2.8187e-05 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9881\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 3.7730e-05 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9881\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 2.3403e-05 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9881\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 2.6127e-05 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9881\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 2.3862e-05 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9881\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 2.8772e-05 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9881\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 4.2210e-05 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9881\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 3.1451e-05 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9881\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 2.4967e-05 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 0.9881\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 2.1558e-05 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9881\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 2.1143e-05 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9881\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 3.3238e-05 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9881\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.6586e-05 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9881\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 2.0433e-05 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9881\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 3.3343e-05 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9881\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 2.1233e-05 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9881\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 2.5764e-05 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 0.9881\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.7402e-05 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9881\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.5071e-05 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9881\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.9860e-05 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9881\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 2.3834e-05 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9881\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 2.7973e-05 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 0.9881\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 2.7612e-05 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 0.9881\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 3.3253e-05 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 0.9881\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 2.3795e-05 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 0.9881\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 2.5615e-05 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9881\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 2.0073e-05 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9881\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.6231e-05 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9881\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 1.5258e-05 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 0.9881\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 2.0659e-05 - accuracy: 1.0000 - val_loss: 0.0265 - val_accuracy: 0.9881\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 1.6747e-05 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 0.9881\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 1.6102e-05 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9881\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 1.2417e-05 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9881\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 1.2395e-05 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9881\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 1.4231e-05 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 0.9881\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.6802e-05 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 0.9881\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 1.3526e-05 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9881\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 3.1425e-05 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 0.9881\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.3705e-05 - accuracy: 1.0000 - val_loss: 0.0259 - val_accuracy: 0.9881\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 2.3320e-05 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9881\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 3.8001e-05 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9881\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.0013 - accuracy: 0.9985 - val_loss: 0.0210 - val_accuracy: 0.9881\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.0223 - accuracy: 0.9910 - val_loss: 0.0143 - val_accuracy: 0.9821\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.0082 - accuracy: 0.9880 - val_loss: 0.1770 - val_accuracy: 0.9048\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.0014 - accuracy: 0.9985 - val_loss: 0.5582 - val_accuracy: 0.7619\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.0029 - accuracy: 0.9970 - val_loss: 0.1323 - val_accuracy: 0.9107\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.0022 - accuracy: 0.9985 - val_loss: 0.0380 - val_accuracy: 0.9583\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 4.7318e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.0033 - accuracy: 0.9985 - val_loss: 3.9963e-04 - val_accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 4.9533e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9940\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 6.8087e-04 - accuracy: 0.9985 - val_loss: 0.0033 - val_accuracy: 0.9940\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.7098e-04 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9940\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 4.9452e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 8.8028e-05 - accuracy: 1.0000 - val_loss: 2.4602e-04 - val_accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 2.1884e-04 - accuracy: 1.0000 - val_loss: 1.1544e-04 - val_accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.5909e-04 - accuracy: 1.0000 - val_loss: 4.2757e-05 - val_accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.4024e-04 - accuracy: 1.0000 - val_loss: 1.9866e-05 - val_accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 7.2539e-05 - accuracy: 1.0000 - val_loss: 1.4288e-05 - val_accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 8.8996e-05 - accuracy: 1.0000 - val_loss: 1.1075e-05 - val_accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 8.5721e-05 - accuracy: 1.0000 - val_loss: 1.0190e-05 - val_accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 6.1002e-05 - accuracy: 1.0000 - val_loss: 1.0288e-05 - val_accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 6.3043e-05 - accuracy: 1.0000 - val_loss: 1.2542e-05 - val_accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 8.1320e-05 - accuracy: 1.0000 - val_loss: 1.3415e-05 - val_accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.5621e-04 - accuracy: 1.0000 - val_loss: 1.3204e-05 - val_accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 2.9824e-05 - accuracy: 1.0000 - val_loss: 1.1880e-05 - val_accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 4.8355e-05 - accuracy: 1.0000 - val_loss: 1.2182e-05 - val_accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 5.0489e-05 - accuracy: 1.0000 - val_loss: 1.3065e-05 - val_accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 5.8196e-05 - accuracy: 1.0000 - val_loss: 1.3475e-05 - val_accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 5.4982e-05 - accuracy: 1.0000 - val_loss: 1.4440e-05 - val_accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 5.6632e-05 - accuracy: 1.0000 - val_loss: 1.5864e-05 - val_accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 3.8708e-05 - accuracy: 1.0000 - val_loss: 1.7589e-05 - val_accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 6.8425e-05 - accuracy: 1.0000 - val_loss: 1.9062e-05 - val_accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 3.8626e-05 - accuracy: 1.0000 - val_loss: 2.0345e-05 - val_accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 4.4386e-05 - accuracy: 1.0000 - val_loss: 2.1736e-05 - val_accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 9.0246e-05 - accuracy: 1.0000 - val_loss: 2.2211e-05 - val_accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 3.0079e-05 - accuracy: 1.0000 - val_loss: 2.2157e-05 - val_accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 4.7469e-05 - accuracy: 1.0000 - val_loss: 2.1301e-05 - val_accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 3.3414e-05 - accuracy: 1.0000 - val_loss: 2.1367e-05 - val_accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 4.4513e-05 - accuracy: 1.0000 - val_loss: 2.0864e-05 - val_accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 4.6442e-05 - accuracy: 1.0000 - val_loss: 2.0280e-05 - val_accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 2.5982e-05 - accuracy: 1.0000 - val_loss: 1.8941e-05 - val_accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 6.3621e-04 - accuracy: 0.9985 - val_loss: 1.2691e-05 - val_accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 7.6163e-05 - accuracy: 1.0000 - val_loss: 1.2058e-05 - val_accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 4.3984e-05 - accuracy: 1.0000 - val_loss: 1.0879e-05 - val_accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 2.7770e-05 - accuracy: 1.0000 - val_loss: 9.5025e-06 - val_accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 4.5064e-05 - accuracy: 1.0000 - val_loss: 8.2359e-06 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 200\n",
        "model = hybrid_model()\n",
        "history = model.fit(train_x, train_y, validation_data=(test_x, test_y), epochs = n_epochs, batch_size = 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OUgbdt0Ib7-",
        "outputId": "e65e7c93-e3be-47a2-c17f-cd19a957a40d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 1s 4ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred =np.squeeze(model.predict(test_x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "L5vdPKkORjrN"
      },
      "outputs": [],
      "source": [
        "for i in range(len(y_pred)):\n",
        "  if y_pred[i]>0.5:\n",
        "    y_pred[i]=1\n",
        "  else:\n",
        "    y_pred[i]=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQAIx3TJTB_X",
        "outputId": "dcb030fa-b381-4908-e8f8-1e4d120c44c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1] [ 59 109]\n"
          ]
        }
      ],
      "source": [
        "unique_values, counts = np.unique(test_y, return_counts=True)\n",
        "print(unique_values, counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32HSavWRUgeF",
        "outputId": "f7557612-ddad-482a-afff-8700c1bb54a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 1.] [ 59 109]\n"
          ]
        }
      ],
      "source": [
        "unique_values, counts = np.unique(y_pred, return_counts=True)\n",
        "print(unique_values, counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j76p3r5CVQCd",
        "outputId": "08bcd69d-e32d-4507-eaf4-5a90e2241df6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     no fall       1.00      1.00      1.00        59\n",
            "        fall       1.00      1.00      1.00       109\n",
            "\n",
            "    accuracy                           1.00       168\n",
            "   macro avg       1.00      1.00      1.00       168\n",
            "weighted avg       1.00      1.00      1.00       168\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(test_y, y_pred, target_names=['no fall', 'fall']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWpYR2BrVrT9",
        "outputId": "9d955e24-9528-4ad4-d5c8-b82ac61a312a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 59   0]\n",
            " [  0 109]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(test_y, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21GE3lbDLFvk"
      },
      "outputs": [],
      "source": [
        "model.save(\"modelpresentation.h5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyP0uoTfh8K1Olm6HgO20Rhv",
      "gpuType": "T4",
      "include_colab_link": true,
      "mount_file_id": "1v8JTUQ1BqYCLMzlp1f6OV-9w_ikB_tqs",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
